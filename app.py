from flask import Flask, render_template, request, jsonify, Response
import json
import os
from datetime import datetime
import requests
from utils.text_processor import split_text, clean_and_format_text
from youtube_handler import YoutubeHandler
from utils.chat_storage import (
    create_new_conversation,
    add_message_to_conversation,
    get_conversation_by_id,
    get_conversation_history
)

app = Flask(__name__, static_folder='static')
app.secret_key = 'sua_chave_secreta_aqui'

API_URL = "http://localhost:11434/v1/chat/completions"
MODEL_NAME = "gemma2:2b"
youtube_handler = YoutubeHandler()

@app.route('/')
def home():
    conversations = get_conversation_history()
    return render_template('index.html', conversations=conversations)

@app.route('/get_conversation_history')
def conversation_history():
    conversations = get_conversation_history()
    return jsonify(conversations)

@app.route('/get_conversation/<conversation_id>')
def get_conversation(conversation_id):
    conversation = get_conversation_by_id(conversation_id)
    if conversation:
        return jsonify(conversation)
    return jsonify({'error': 'Conversa não encontrada'}), 404

@app.route('/send_message', methods=['POST'])
def send_message():
    data = request.json
    message = data.get('message', '')
    conversation_id = data.get('conversation_id')

    if not conversation_id:
        conversation_id = create_new_conversation()

    # Salvar mensagem do usuário
    add_message_to_conversation(conversation_id, message, "user")

    # Processar resposta da IA
    accumulated_response = []
    
    def generate_streamed_response():
        for part in process_with_ai_stream(message):
            if part:
                accumulated_response.append(part)
                yield f"data: {json.dumps({'content': part})}\n\n"
        
        # Salvar a resposta completa da IA
        if accumulated_response:
            complete_response = ''.join(accumulated_response)
            add_message_to_conversation(conversation_id, complete_response, "assistant")

    response = Response(generate_streamed_response(), content_type="text/event-stream")
    response.headers['Cache-Control'] = 'no-cache'
    return response

def process_with_ai(text):
    try:
        payload = {
            "model": MODEL_NAME,
            "messages": [
                {"role": "system", "content": "Você é um assistente útil."},
                {"role": "user", "content": text}
            ],
            "stream": False
        }
        headers = {"Content-Type": "application/json"}
        response = requests.post(API_URL, json=payload, headers=headers)
        response.raise_for_status()

        response_data = response.json()
        if 'choices' in response_data and len(response_data['choices']) > 0:
            return response_data['choices'][0]['message']['content']
        return "Erro: Nenhuma resposta válida recebida da IA."
    except requests.exceptions.RequestException as e:
        print(f"[Debug] Erro na requisição HTTP: {str(e)}")
        return "Ocorreu um erro ao se conectar com a IA."
    except Exception as e:
        print(f"[Debug] Erro inesperado: {str(e)}")
        return "Ocorreu um erro inesperado ao processar sua mensagem."

def process_with_ai_stream(text):
    try:
        payload = {
            "model": MODEL_NAME,
            "messages": [
                {"role": "system", "content": "Você é um assistente útil."},
                {"role": "user", "content": text}
            ],
            "stream": True
        }
        headers = {"Content-Type": "application/json"}
        response = requests.post(API_URL, json=payload, headers=headers, stream=True)
        response.raise_for_status()

        for line in response.iter_lines(decode_unicode=True):
            if line.strip() and line.startswith("data: "):
                line = line[6:].strip()
                try:
                    response_data = json.loads(line)
                    if 'choices' in response_data and len(response_data['choices']) > 0:
                        delta = response_data['choices'][0]['delta']
                        if "content" in delta:
                            content = delta["content"].encode('latin1').decode('utf-8', errors='ignore')
                            yield content
                except json.JSONDecodeError:
                    print(f"[Debug] Erro ao decodificar JSON: {line}")
    except requests.exceptions.RequestException as e:
        print(f"[Debug] Erro na requisição HTTP: {str(e)}")
    except Exception as e:
        print(f"[Debug] Erro inesperado: {str(e)}")

@app.route('/process_youtube', methods=['POST'])
def process_youtube():
    data = request.json
    video_url = data.get('video_url')
    
    if not video_url:
        return jsonify({'error': 'URL do vídeo não fornecida'}), 400
        
    # Baixa as legendas
    subtitle_file = youtube_handler.download_subtitles(video_url)
    if not subtitle_file:
        return jsonify({'error': 'Não foi possível baixar as legendas'}), 400
        
    # Limpa as legendas
    subtitle_text = youtube_handler.clean_subtitles(subtitle_file)
    if not subtitle_text:
        return jsonify({'error': 'Erro ao processar legendas'}), 500
        
    # Limpa e formata o texto
    cleaned_text = clean_and_format_text(subtitle_text)
    
    # Divide em chunks
    chunks = split_text(cleaned_text)
    
    # Cria uma nova conversa
    conversation_id = create_new_conversation()
    
    # Salva os chunks para processamento
    for chunk in chunks:
        add_message_to_conversation(conversation_id, chunk, 'user')
    
    return jsonify({
        'status': 'success',
        'conversation_id': conversation_id,
        'message': 'Legendas processadas com sucesso'
    })

if __name__ == '__main__':
    app.run(debug=True)
